智联
前程无忧
猎聘
拉钩
BOSS直聘
赶集
58



爬虫


爬虫分类：异步爬虫 ---- Ajax
		   ---- selenium（测试框架）
		   ---- 网页分析
	  增量爬虫 ---- 一个url，不同的时间返回的内容不同
	  移动端app爬虫 ---- 抓包工具 ：fiddler
					Charles
					wires hark
	  pc爬虫
	  分布式爬虫 ---- 通过scrapy框架来实现

url：   url时uri的一个子类
	url的去重：将爬取过的url放在一个列表中
		   布隆过滤器
		   给每个url算一个哈希值
		   当数量级不是很大时，数据库可去重
	url的组成 ---- 协议（常用的是https）：//服务器主机地址（用户名：密码@子域名，域名，顶级域名）；		       端口（HTTP协议默认的是80端口）/路径（目录/文件名.文件后缀）参数（查询搜索的部分		       ，需要向服务器传入参数，就在这输入。通过问号？连接到path后面，有时候也归类到			       path中。一般来说，参数都是键值一一对应着，名和值用等号=隔开，task=4640 。参数可			       以有多个，参数之间用“&”分隔。）

		       常见的端口有：数据库Oracle：1521；  Mysql：3306； FTP：21 ； SSH：22

 
爬虫攻防战： 突破反爬： 添加各种参数 ---- user-agent（伪装成浏览器）
			             ---- referer：来源（伪装成点击进入，而不是跳转）
			代理：IP代理池
			cookie池
			

	     反爬：目的 --- 区分人和机器（非人）
		   措施 --- 验证码（拼图，成语，计算，排序，倒立（将倒立的字点出））
			    ---- 验证码的解决方案：1、绕过验证码
					  	   2、人工打码
					  	   3、调用别人提供的API
		        --- 封IP
			--- 封帐号

爬取策略：深度优先
	  广度优先

其他：八爪鱼（爬虫工具）
      熊猫（采集工具）

下载器：requests
	urllib（python自带的，但功能性不强）

解析器：正则，xpath,bs

数据的后续处理：保存成文件，数据分析，存入数据库或磁盘中


