回顾爬虫:

url  统一资源定位符 
urlA  通常事某网站得首页,起始url
###url  去重方式:
	1.放在set里边   每次爬得时候先判断是否爬过此链接
	2. 布隆过滤器
	3. 给每个url算一个哈希值   什么是哈希
	4.数据库去重

###下载器
	requests   请求
	urllib
	

###解析器
	1.正则
	2.xpath
	3.beautiful soup  

###数据后续处理:
	1.保存成文件
	2.数据分析
	3.存入数据库


###爬虫攻防战
	 	
	
	反爬  : 
		验证码:  成语
		             拼图
		             计算的
		             排顺序
		             倒立    
	                验证码解决方案 : 自己写库
			          绕过验证码
			          人工打码
			          调用别人提供得api
	                目的:  区分人和机器人
	
	突破反爬:
		添加user_agent:   伪装成浏览器 
		代理:   尽量用代理IP   IP代理池
		cooking池:  账号密码                  换着用ip和账号
		header中添加各种参数:  referer   来源,  以及其他参数   
	
###爬虫分类:
	异步爬虫:  ajax
		selenium  
		网页分析
	增量爬虫:	一个url不同时间返回内容不同
	移动端APP爬虫:抓包工具:  Charles,,fiddler,,wires hark
	pc爬虫:
###爬取策略:
	深度优先
	广度优先