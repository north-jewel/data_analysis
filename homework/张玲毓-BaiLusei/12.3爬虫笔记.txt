selenium  驱动浏览器  做自动化测试  直接执行 js渲染

Chromewebdriver  谷歌驱动器

phantomjs  

什么是爬虫 ？
请求 网站并 提取 数据的 自动化 程序

爬虫的基本流程：
1.向服务器发起请求 request
2.获取响应内容  返回response
3.解析内容
4.保存数据

请求的四部分内容：
requests  常用的请求类型：

get 和 post 的区别
  
	get可以直接跟url  回车直接访问  
	需要请求的参数信息全都包含在url里边

  	post需要构建一个表单，进行表单提交才可以构造post请求
  	请求信息保存在form data里边
请求url:
url 统一资源定位符

请求头 requests headers:
配置信息：
	cookie  用来保持登陆绘画
	
	user.agent 指定浏览器请求头，服务器识别浏览器 才会发送响应 

请求体：
post
	form data 字典的形式
get  
	一般没有请求体


resoponse中包含的内容
1.响应状态
	200状态码  表示访问成功
	301状态码  用来跳转
	404状态码  找不到页面
	502状态码  服务器处理错误

2.响应头
	response headers  内容类型、内容长度、服务器信息、设置cookie等等
3.响应体 response
	包含了请求资源的内容，网页HTML、图片、二进制数据等


能抓怎样的数据？ 
	HTML文本、JSON文本、图片的二进制流、视频、其他的比如文档，都可以用二进制的方式抓取下来
 

解析方式：
1、直接处理，最简单的方法，返回字符串  去除头尾共额  
2、json解析，字符串解析   转换成json  
3、正则表达式    规则字符串  html相应的文本提出来
4、解析库  beautifulSoup  
5、PyQuery
6、XPath



尽量使用泛匹配，使用括号得到匹配目标，尽量使用非贪婪模式，有换行符就用re.S















